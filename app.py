import streamlit as st
import logging
import os
from utils.bedrock_lib import BedrockRAG

# ë¡œê¹… ì„¤ì •
log_level = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=getattr(logging, log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

PAGE_TITLE = "í•œêµ­ê¸ˆìœµê·œì œ ê´€ë ¨ Q&A ì±„íŒ…ë´‡"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=PAGE_TITLE,
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ëª¨ë¸ ì˜µì…˜ ì •ì˜
MODEL_OPTIONS = {
    "Claude Sonnet 4": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "Claude 3.7 Sonnet": "apac.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "Amazon Nova Pro": "apac.amazon.nova-pro-v1:0"
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "selected_model" not in st.session_state:
    st.session_state.selected_model = "Claude 3.7 Sonnet"

if "bedrock_rag" not in st.session_state:
    st.session_state.bedrock_rag = BedrockRAG(model_id=MODEL_OPTIONS[st.session_state.selected_model])

if "max_tokens" not in st.session_state:
    st.session_state.max_tokens = 4000

if "temperature" not in st.session_state:
    st.session_state.temperature = 0.0

if "top_p" not in st.session_state:
    st.session_state.top_p = 0.9

if "max_results" not in st.session_state:
    st.session_state.max_results = 5

# ì‚¬ì´ë“œë°” - ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ëª¨ë¸ ì„ íƒ
    selected_model = st.selectbox(
        "ëª¨ë¸ ì„ íƒ:",
        options=list(MODEL_OPTIONS.keys()),
        index=list(MODEL_OPTIONS.keys()).index(st.session_state.selected_model)
    )
    
    # ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œ ì—…ë°ì´íŠ¸
    if selected_model != st.session_state.selected_model:
        st.session_state.selected_model = selected_model
        st.session_state.bedrock_rag = BedrockRAG(model_id=MODEL_OPTIONS[selected_model])
        st.rerun()
    
    st.divider()
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
    st.subheader("ğŸ›ï¸ ëª¨ë¸ íŒŒë¼ë¯¸í„°")
    
    max_tokens = st.slider(
        "Max Tokens:",
        min_value=100,
        max_value=8000,
        value=st.session_state.max_tokens,
        step=100
    )
    
    temperature = st.slider(
        "Temperature:",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.temperature,
        step=0.1
    )
    
    top_p = st.slider(
        "Top P:",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.top_p,
        step=0.1
    )
    
    st.divider()
    
    # ê²€ìƒ‰ ì„¤ì •
    st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    
    max_results = st.number_input(
        "ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜:",
        min_value=1,
        max_value=20,
        value=st.session_state.max_results,
        step=1
    )
    
    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    st.session_state.max_tokens = max_tokens
    st.session_state.temperature = temperature
    st.session_state.top_p = top_p
    st.session_state.max_results = max_results


def extract_filename_from_location(location):
    """S3 Locationì—ì„œ íŒŒì¼ëª…ì„ ì¶”ì¶œí•˜ëŠ” ë©”ì†Œë“œ"""
    if location and 's3Location' in location:
        s3_uri = location['s3Location'].get('uri', '')
        if s3_uri:
            return s3_uri.split('/')[-1]
    return "ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼"

def display_reference_documents(kb_results):
    """ì°¸ê³  ë¬¸ì„œ ë° ì¸ìš© ì •ë³´ë¥¼ í‘œì‹œí•˜ëŠ” ë©”ì†Œë“œ"""
    with st.expander(f"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(kb_results)}ê°œ)"):
        for i, result in enumerate(kb_results, 1):
            location = result.get('location', {})
            filename = extract_filename_from_location(location)
            
            st.write(f"**ë¬¸ì„œ {i}:** `{filename}` (ì ìˆ˜: {result.get('score', 'N/A'):.3f})")
            st.write(f"ì¶œì²˜: {filename}")
            doc_content = result["content"]
            st.write(doc_content[:300] + "..." if len(doc_content) > 300 else doc_content)
            st.divider()

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.title(f"ğŸ¤– {PAGE_TITLE}")
st.caption(f"Amazon Bedrock Knowledge Baseë¥¼ í™œìš©í•œ RAG ê¸°ë°˜ ì±„íŒ…ë´‡ì…ë‹ˆë‹¤. (í˜„ì¬ ëª¨ë¸: {st.session_state.selected_model})")

# ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        # Knowledge Baseì—ì„œ ê²€ìƒ‰
        kb_results = []
        context = ""
        if st.session_state.bedrock_rag.knowledge_base_id:
            with st.spinner("ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                kb_results = st.session_state.bedrock_rag.retrieve_only(prompt, max_results=st.session_state.max_results)
                context_docs = [result["content"] for result in kb_results]
                context = "\n\n".join(context_docs) if context_docs else ""
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ ì‘ë‹µ ìƒì„±
        if kb_results:
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            response_placeholder = st.empty()
            full_response = ""
            
            for chunk in st.session_state.bedrock_rag.generate_response_stream(
                prompt, 
                context, 
                max_tokens=st.session_state.max_tokens,
                temperature=st.session_state.temperature,
                top_p=st.session_state.top_p
            ):
                full_response += chunk
                response_placeholder.markdown(full_response + "â–Œ")
            
            response_placeholder.markdown(full_response)
            
            # ì°¸ê³  ë¬¸ì„œ ë° ì¸ìš© ì •ë³´ í‘œì‹œ
            display_reference_documents(kb_results)
        else:
            full_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ ë³´ì„¸ìš”."
            st.markdown(full_response)
            
            if not st.session_state.bedrock_rag.knowledge_base_id:
                st.info("ğŸ’¡ í™˜ê²½ ë³€ìˆ˜ì—ì„œ KNOWLEDGE_BASE_IDë¥¼ ì„¤ì •í•˜ë©´ RAG ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        response = full_response
    
    # AI ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
col1, col2 = st.columns([1, 4])
with col1:
    if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()